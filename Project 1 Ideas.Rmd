---
title: "Macroeconometrics, Empirical project"
author:
- Samuel, ^[student ID 00000000]
- Hochholzer Matthias^[student ID 11724853]
date: "xxth June 2021"
output:
  pdf_document:
    number_sections: true
    toc: true
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lastpage}
- \usepackage{graphicx}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[L]{Empirical project}
- \fancyhead[R]{\thepage\ of \pageref{LastPage}}
- \fancyfoot[R]{\includegraphics[width=3cm]{Uni_Logo_blau.png}}
- \fancyfoot[C]{}
- \setlength{\footskip}{46.27646pt}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
\newpage
# Idea

We want to look at the relationship between certain prices and the respective search interest on Google for these prices. Can we find granger causality for this relationship? What are possible issues? For example: modern trading algorithms scrape data from the internet and then buy or sell based on the sentiment. Large spikes in search interest may trigger such algorithms. As media spreads the news of price increases more people will look up prices of goods and commodities, again triggering the algorithms. This is basically a feedback loop.

# Data

First some notes on the data. The data on the search index of certain prices is taken from Google trends which collects the search queries of people within a specific region (here: United States of America). This data is aggregated on a monthly basis and normalized with a range from zero to 100. Already filtered out are duplicate searches in the sense that the same user made the same search multiple times within a short time-frame. This way we exclude the users which have already invested and constantly checked the prices to look how their investment is doing. Data points are divided by total searches for the month and region to represent the relative popularity, i.e.\ no over-weighting of regions with more people than others which would, given the same search behavior, lead to differing popularities otherwise. 

The data on gold prices comes form the London Bullion Market Association Gold Price and the Federal Reserve Bank of St. Louis. It is measured in USD per troy, daily at 3:00pm. Aggregation is done via prices at the end of each month and it is not seasonally adjusted.

In parts of this project we scale the price and search index to a range from zero to one in order to compare the relative movements more easily. 

# Project Code
```{r 1, message=FALSE, warning=FALSE}
# clear workspace 
rm(list=ls())

# load needed libraries
library(readr)
library(vars)

# set working directory
#setwd("/Users/samue/Downloads/Studium/Economics (Master - Vienna)/2. Semester/Macroeconometrics/Project/macroeconometrics_prices")

# import search trends
data <-  read_csv("btc-vs-gold-2004.csv", col_types = cols(Month = col_date(format = "%Y-%m")))
# import prices data:
gold_pr <- read_csv("gold-2004.csv", col_types = cols(DATE = col_date(format = "%Y-%m-%d")))
```

```{r 1.1}
# plot gold price
plot(y=gold_pr$GOLDPMGBD228NLBM,x=gold_pr$DATE,type = 'l', lwd = 2, col = 'red',
     ylim = c(0,2000), main = 'Gold Price and Search Interest',
     xlab = 'Time', ylab = 'Search Interest (scaled) & Price (unscaled)')
# add gold search interest scaled up 
lines(y=25*data$GOLD,x=gold_pr$DATE, lwd = 2, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))



# create first differenced prices and search interest
t <- length(gold_pr$DATE)
gold_price_FD <- rep(0,t-1)
for(i in 2:209){gold_price_FD[i-1] <- gold_pr$GOLDPMGBD228NLBM[i]-gold_pr$GOLDPMGBD228NLBM[i-1]}
gold_search_FD <- rep(0,t-1)
for(i in 2:209){gold_search_FD[i-1] <- data$GOLD[i]-data$GOLD[i-1]}

# plot first differenced variables
plot(y=gold_price_FD,x=gold_pr$DATE[1-209], type = 'l', lwd = 1, col = 'red',
     xlab = 'Time', ylab = '1-Period Differences',
     main = 'First Differences: Gold Price and Search Interest')
lines(y=gold_search_FD*8,x=gold_pr$DATE[1-209], lwd = 1, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))
```
Visually, it appears that the more volatile periods match. An issue seems to be the scaling of the variables. 
```{r 2}
# plot ACF for unmodified variables:
par(mfrow=c(2,2))     # changes the plot layout to more easily compare them
acf(gold_pr$GOLDPMGBD228NLBM, main = 'ACF Gold Price')
acf(data$GOLD, main = 'ACF Gold Search Interest')

# plot PACF for unmodified variables:
pacf(gold_pr$GOLDPMGBD228NLBM, main = 'PACF Gold Price')
pacf(data$GOLD, main = 'PACF Gold Search Interest')

# plot ACF for differenced variables
acf(gold_price_FD,main = 'ACF Gold Price FD')
acf(gold_search_FD, main = 'ACF Gold Search Interest FD')

# plot PACF for differenced variables
pacf(gold_price_FD,main = 'PACF Gold Price FD')
pacf(gold_search_FD, main = 'PACF Gold Search Interest FD')
par(mfrow = c(1,1))   # revert layout changes
```
Autocorrelation for the differenced variables seems like no month-on-month relationship between the changes. Kind of like a random walk?

Might help with the interpretation: scale all variables $\mathbf X$ such that $X_t \in [0,1] \forall t \in T$.
```{r 3}
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
plot(y=range01(gold_pr$GOLDPMGBD228NLBM),x=gold_pr$DATE, lwd = 2, type = 'l',
     ylab = 'Scaled Price and Search Interest',
     xlab = 'Time', col = 'red')
lines(y=range01(data$GOLD),x=gold_pr$DATE, lwd = 2, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# save scaled variables
gold_price_scaled <- range01(gold_pr$GOLDPMGBD228NLBM)
gold_search_scaled <- range01(data$GOLD)

# create first difference on scaled variables:
gold_search_scaled_FD <- rep(0,t-1)
gold_price_scaled_FD <- rep(0,t-1)

for(i in 2:t-1){
  gold_price_scaled_FD[i-1] <- gold_price_scaled[i]-gold_price_scaled[i-1]
}
for(i in 2:t-1){
  gold_search_scaled_FD[i-1] <- gold_search_scaled[i]-gold_search_scaled[i-1]
}

# plot first differenced:
plot(y=gold_price_scaled_FD, x=gold_pr$DATE[1-209], lwd = 1, type = 'l',
     ylab = 'FD Scaled Price and Search Interest',
     xlab = 'Time', col = 'red')
lines(y= gold_search_scaled_FD, x=gold_pr$DATE[1-209], lwd = 1, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# plot ACFs
par(mfrow=c(2,2))     # changes the plot layout to more easily compare them
acf(gold_price_scaled, main = 'ACF Scaled Gold Price')
acf(gold_search_scaled, main = 'ACF Scaled Gold Search Interest')
acf(gold_price_scaled_FD,main = 'ACF Scaled Gold Price FD')
acf(gold_search_scaled_FD, main = 'ACF Scaled Gold Search Interest FD')
par(mfrow = c(1,1))   # revert layout changes


# plot PACFs
par(mfrow=c(2,2))     # changes the plot layout to more easily compare them
pacf(gold_price_scaled, main = 'PACF Scaled Gold Price')
pacf(gold_search_scaled, main = 'PACF Scaled Gold Search Interest')
pacf(gold_price_scaled_FD,main = 'PACF Scaled Gold Price FD')
pacf(gold_search_scaled_FD, main = 'PACF Scaled Gold Search Interest FD')
par(mfrow = c(1,1))   # revert layout changes
```
Unsurprisingly the rescaling does not matter for the autocorrelation as it is a scaled measure of linear relationships anyway.

ACF Scaled Gold Search Interest FD together with PACF Scaled Gold Search Interest FD gives evidence for an AR(4).

For the Gold Price it's as you say. Could be a MA(1), AR(1) or an ARMA. 

#####################################################
####### Should we also do DF for gold_search? #####
#####################################################
```{r 4}
#####################################################
####### From here on: data saved as time series #####
#####################################################

# save variable vectors as time series format:
gold_price_scaled <- ts(gold_price_scaled, frequency = 12,
                        start = c(2004, 1), end = c(2021, 5))
gold_search_scaled <- ts(gold_search_scaled, frequency = 12,
                         start = c(2004,1), end = c(2021,5))

# set up data for estimation using `VAR()`
VAR_data <- window(ts.union(gold_price_scaled, gold_search_scaled),
                   start = c(2004, 1), end = c(2021, 5))

# estimate model coefficients using `VAR()`
VAR_est <- VAR(y = VAR_data, p = 2)
summary(VAR_est)

# augmented df test on only the gold price
df_test_gold_price <- urca::ur.df(gold_price_scaled, type = c('drift'),
                       selectlags = 'BIC')
summary(df_test_gold_price)


#####################################################
####### I also included DF for gold_search #####
#####################################################

# augmented df test on only the gold search
df_test_gold_search <- urca::ur.df(gold_search_scaled, type = c('drift'),
                       selectlags = 'BIC')
summary(df_test_gold_search)
```
For both, the null cannot be rejected given the data, the null is non-stationarity. Not very unexpected for prices, as they are often thought about as following a random walk and thus being non-stationary. But we can also look at difference-stationarity to check.
```{r 5}
# augmented df test on only the differenced gold price
df_test_gold_price_FD <- urca::ur.df(gold_price_scaled_FD, type = 'none',
                               selectlags = 'BIC')
summary(df_test_gold_price_FD)

#####################################################
####### Same here, I included DF for gold_search #####
#####################################################

# augmented df test on only the differenced gold price
df_test_gold_search_FD <- urca::ur.df(gold_search_scaled_FD, type = 'none',
                               selectlags = 'BIC')
summary(df_test_gold_search_FD)
```
As the test rejects, given the data we cannot say that the data is not stationary. Which gives evidence for both being I(1).
```{r 6}
# VAR model with unscaled prices
# save variable vectors as time series format:
gold_price <- ts(gold_pr$GOLDPMGBD228NLBM, frequency = 12,
                        start = c(2004, 1), end = c(2021, 5))
gold_search <- ts(data$GOLD, frequency = 12,
                         start = c(2004,1), end = c(2021,5))

# set up data for estimation using `VAR()`
VAR_data <- window(ts.union(gold_price, gold_search),
                   start = c(2004, 1), end = c(2021, 5))

# estimate model coefficients using `VAR()`
VAR_est <- VAR(y = VAR_data, p = 1, type = 'both')
summary(VAR_est)

#####################################################
####### Sollten wir hier beim AR(1) nicht die First differences verwenden. Weil wir ja einen I(1) prozess haben. Und sollten wir nicht einfach mit dem besteren ARMA modell arbeiten und nicht AR(1) ? #####
#####################################################

# compare the VAR to the AR(1) model for the prices
T <-length(gold_price)
gold_price_2 <- as.numeric(gold_price[-1])
gold_price_lagged <- as.numeric(gold_price[-T])

plot(y=gold_price_2,x=gold_pr$DATE[1-209], type = 'l', lwd = 1, col = 'red',
     main = 'Gold Price and Lagged Gold Price',
     ylab = 'Gold Price', xlab = 'Months from 01.2004')
lines(y=gold_price_lagged,x=gold_pr$DATE[1-209], lwd = 1, col = 'blue')
legend('topleft', legend = c('Lagged Price','Price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# estimate model
gold_price_AR1 <- lm(gold_price_2 ~ gold_price_lagged)
# estimate robust standard errors
coeftest(gold_price_AR1, vcov. = vcovHC, type = "HC1")

#####################################################
####### Hier mal die abgeänderte Version mit AR(1) und FD #####
#####################################################


# compare the VAR to the AR(1) model for the prices first-differences
T <-length(gold_price_FD)
gold_price_FD_2 <- as.numeric(gold_price_FD[-1])
gold_price_FD_lagged <- as.numeric(gold_price_FD[-T])

plot(y=gold_price_FD_2,x=gold_pr$DATE[3:209], type = 'l', lwd = 1, col = 'red',
     main = 'Gold Price FD and Lagged Gold Price FD',
     ylab = 'Gold Price FD', xlab = 'Months from 01.2004')
lines(y=gold_price_FD_lagged,x=gold_pr$DATE[3:209], lwd = 1, col = 'blue')
legend('topleft', legend = c('Lagged Price','Price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# estimate model
gold_price_FD_AR1 <- lm(gold_price_FD_2 ~ gold_price_FD_lagged)
# estimate robust standard errors
coeftest(gold_price_FD_AR1, vcov. = vcovHC, type = "HC1")

```
The values on the intercept seem to differ, but the estimated coefficient on the lag seems to fit. 
```{r 7}
# verify the 'by-hand' results with built-in function
ar.ols(gold_price, order.max = 1, intercept = T)
forecast::auto.arima(gold_price, ic = 'aic')
```
The last model is automated to difference such that the data is stationary, then the function finds the best forecasting model via the AIC. Here this would be an ARMA(0,1) model:
  \begin{align*}
  \widehat{\Delta \text{gold price}}_t = \underset{3.6766}{(7.1279)} + \epsilon_t + \underset{(0.0740)}{(-0.1411)} \epsilon_{t-1}
  \end{align*}

#######################################################################################
# Sollten wir hier nicht mit MA(1) weiterarbeiten ? #
# Ich habs mal weiter unten mit MA(1) gemacht. Den AR(1) part aber noch nicht gelöscht#
#######################################################################################
  
# Differenced AR(1) and ARCH Model for Gold Prices

```{r 8}
# Differenced AR(1) and ARCH Model for Gold Prices 
gold_price_FD <- ts(gold_price_FD, frequency = 12,
                    start = c(2004, 2), end = c(2021, 5))
plot(gold_price_FD, ylab = 'FD Gold Prices', col = 'red', lwd = 1.5)
ar1mod_FD <- arima(gold_price_FD, order = c(1,0,0))
ar1mod_FD
plot(forecast::arima.errors(ar1mod_FD),type = 'l', lwd = 1.5, col = 'blue',
     ylab = 'ARIMA residuals')
mean(forecast::arima.errors(ar1mod_FD))
```
Going by the plot, it does not appear that the variance of the residuals is constant over time but rather has times of higher and lower volatility. 
```{r 9}
resi_ar1_FD_2 <- (forecast::arima.errors(ar1mod_FD))^2
resi_arch1_FD_2_model <- arima(resi_ar1_FD_2, order = c(1,0,0))
resi_arch1_FD_2_model

# plot the squared residuals:
plot(resi_ar1_FD_2, ylab = 'Squared AR(1) Residuals of FD Gold Price',
     xlab = 'Time from 02.2004', col = 'red', lwd = 1.5)
```

############################################### 
# Mit MA(1), ändert nicht viel# 
############################################### 

# Differenced MA(1) and ARCH Model for Gold Prices
```{r}
# Differenced MA(1) and ARCH Model for Gold Prices 
gold_price_FD <- ts(gold_price_FD, frequency = 12,
                    start = c(2004, 2), end = c(2021, 5))
plot(gold_price_FD, ylab = 'FD Gold Prices', col = 'red', lwd = 1.5)
ma1mod_FD <- arima(gold_price_FD, order = c(0,0,1))
ma1mod_FD
plot(forecast::arima.errors(ma1mod_FD),type = 'l', lwd = 1.5, col = 'blue',
     ylab = 'ARIMA residuals')
mean(forecast::arima.errors(ma1mod_FD))
```
Going by the plot, it does not appear that the variance of the residuals is constant over time but rather has times of higher and lower volatility. 
```{r}
resi_ma1_FD_2 <- (forecast::arima.errors(ma1mod_FD))^2
resi_arch1_FD_2_model <- arima(resi_ma1_FD_2, order = c(0,0,1))
resi_arch1_FD_2_model

# plot the squared residuals:
plot(resi_ma1_FD_2, ylab = 'Squared MA(1) Residuals of FD Gold Price',
     xlab = 'Time from 02.2004', col = 'red', lwd = 1.5)
```


