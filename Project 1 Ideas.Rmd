---
title: "Macroeconometrics, Empirical project"
author:
- Samuel Hashem Zehi^[student ID 12012285]
- Hochholzer Matthias^[student ID 11724853]
date: "xxth June 2021"
output:
  pdf_document:
    number_sections: true
    toc: true
header-includes:
- \usepackage{fancyhdr}
- \usepackage{lastpage}
- \usepackage{graphicx}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[L]{Empirical project}
- \fancyhead[R]{\thepage\ of \pageref{LastPage}}
- \fancyfoot[R]{\includegraphics[width=3cm]{Uni_Logo_blau.png}}
- \fancyfoot[C]{}
- \setlength{\footskip}{46.27646pt}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
\newpage
# Idea

We want to look at the relationship between certain prices and the respective search interest on Google for these prices. Can we find granger causality for this relationship? What are possible issues? For example: modern trading algorithms scrape data from the internet and then buy or sell based on the sentiment. Large spikes in search interest may trigger such algorithms. As media spreads the news of price increases more people will look up prices of goods and commodities, again triggering the algorithms. This is basically a feedback loop.

# Data

First some notes on the data. The data on the search index of certain prices is taken from Google trends which collects the search queries of people within a specific region (here: United States of America). This data is aggregated on a monthly basis and normalized with a range from zero to 100. Already filtered out are duplicate searches in the sense that the same user made the same search multiple times within a short time-frame. This way we exclude the users which have already invested and constantly checked the prices to look how their investment is doing. Data points are divided by total searches for the month and region to represent the relative popularity, i.e.\ no over-weighting of regions with more people than others which would, given the same search behavior, lead to differing popularities otherwise. 

The data on gold prices comes form the London Bullion Market Association Gold Price and the Federal Reserve Bank of St. Louis. It is measured in USD per troy, daily at 3:00pm. Aggregation is done via prices at the end of each month and it is not seasonally adjusted.

In parts of this project we scale the price and search index to a range from zero to one in order to compare the relative movements more easily. 

# Project Code
```{r 1, message=FALSE, warning=FALSE}
# clear workspace 
rm(list=ls())

# load needed libraries
library(readr)
library(vars)
library(zoo)
library(tseries)
library(rugarch)

# set working directory
#setwd("/Users/samue/Downloads/Studium/Economics (Master - Vienna)/2. Semester/Macroeconometrics/Project/macroeconometrics_prices")

# import search trends
data <-  read_csv("btc-vs-gold-2004.csv", col_types = cols(Month = col_date(format = "%Y-%m")))
# import prices data:
gold_pr <- read_csv("gold-2004.csv", col_types = cols(DATE = col_date(format = "%Y-%m-%d")))
# import high-frequency prices for gold:
gold_HF <- read_csv('gold-2001-HF.csv', col_types = cols(DATE = col_date(format = '%Y-%m-%d'),GOLDPMGBD228NLBM = col_double()))

#renaming variables
gold_price <- gold_pr$GOLDPMGBD228NLBM
gold_price_HF <- gold_HF$GOLDPMGBD228NLBM
gold_price_HF <- na.locf(gold_price_HF)
gold_date <- gold_pr$DATE
gold_search <- data$GOLD
```

```{r 1.1}
# plot gold price on monthly basis
plot(y=gold_price,x=gold_date,type = 'l', lwd = 2, col = 'red',
     ylim = c(0,2000), main = 'Gold Price and Search Interest',
     xlab = 'Time', ylab = 'Search Interest (scaled) & Price (unscaled)')
# add gold search interest scaled up 
lines(y=25*gold_search,x=gold_date, lwd = 2, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# create first differenced prices and search interest
t <- length(gold_date)
gold_price_FD <- rep(0,t-1)
for(i in 2:209){gold_price_FD[i-1] <- gold_price[i]-gold_price[i-1]}
gold_search_FD <- rep(0,t-1)
for(i in 2:209){gold_search_FD[i-1] <- gold_search[i]-gold_search [i-1]}
t_1 <- length(gold_HF$DATE)
gold_daily_FD <- rep(0,t_1-1)
for(i in 2:5332){gold_daily_FD[i-1] <- gold_price_HF[i]-gold_price_HF[i-1]}

# plot first differenced variables
plot(y=gold_price_FD,x=gold_pr$DATE[1-209], type = 'l', lwd = 1, col = 'red',
     xlab = 'Time', ylab = '1-Period Differences',
     main = 'First Differences: Gold Price and Search Interest')
lines(y=gold_search_FD*8,x=gold_pr$DATE[1-209], lwd = 1, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))
```
Visually, it appears that the more volatile periods match. An issue seems to be the scaling of the variables.
```{r 2}
# plot ACF for unmodified variables:
par(mfrow=c(2,2))     # changes the plot layout to more easily compare them
acf(gold_pr$GOLDPMGBD228NLBM, main = 'ACF Gold Price')
acf(data$GOLD, main = 'ACF Gold Search Interest')

# plot PACF for unmodified variables:
pacf(gold_pr$GOLDPMGBD228NLBM, main = 'PACF Gold Price')
pacf(data$GOLD, main = 'PACF Gold Search Interest')

# plot ACF for differenced variables
acf(gold_price_FD,main = 'ACF Gold Price FD')
acf(gold_search_FD, main = 'ACF Gold Search Interest FD')

# plot PACF for differenced variables
pacf(gold_price_FD,main = 'PACF Gold Price FD')
pacf(gold_search_FD, main = 'PACF Gold Search Interest FD')
par(mfrow = c(1,1))   # revert layout changes
```

It might help with the interpretation: scale all variables $\mathbf X$ such that $X_t \in [0,1] \forall t \in T$.
```{r 3}
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
plot(y=range01(gold_pr$GOLDPMGBD228NLBM),x=gold_pr$DATE, lwd = 2, type = 'l',
     ylab = 'Scaled Price and Search Interest',
     xlab = 'Time', col = 'red')
lines(y=range01(data$GOLD),x=gold_pr$DATE, lwd = 2, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# save scaled variables
gold_price_scaled <- range01(gold_pr$GOLDPMGBD228NLBM)
gold_search_scaled <- range01(data$GOLD)

# create first difference on scaled variables:
gold_search_scaled_FD <- rep(0,t-1)
gold_price_scaled_FD <- rep(0,t-1)

for(i in 2:t-1){
  gold_price_scaled_FD[i-1] <- gold_price_scaled[i]-gold_price_scaled[i-1]
}
for(i in 2:t-1){
  gold_search_scaled_FD[i-1] <- gold_search_scaled[i]-gold_search_scaled[i-1]
}

# plot first differenced:
plot(y=gold_price_scaled_FD, x=gold_pr$DATE[1-209], lwd = 1, type = 'l',
     ylab = 'FD Scaled Price and Search Interest',
     xlab = 'Time', col = 'red')
lines(y= gold_search_scaled_FD, x=gold_pr$DATE[1-209], lwd = 1, col = 'blue')
legend('topleft', legend = c('search','price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# plot ACFs
par(mfrow=c(2,2))     # changes the plot layout to more easily compare them
acf(gold_price_scaled, main = 'ACF Scaled Gold Price')
acf(gold_search_scaled, main = 'ACF Scaled Gold Search Interest')
acf(gold_price_scaled_FD,main = 'ACF Scaled Gold Price FD')
acf(gold_search_scaled_FD, main = 'ACF Scaled Gold Search Interest FD')
par(mfrow = c(1,1))   # revert layout changes


# plot PACFs
par(mfrow=c(2,2))     # changes the plot layout to more easily compare them
pacf(gold_price_scaled, main = 'PACF Scaled Gold Price')
pacf(gold_search_scaled, main = 'PACF Scaled Gold Search Interest')
pacf(gold_price_scaled_FD,main = 'PACF Scaled Gold Price FD')
pacf(gold_search_scaled_FD, main = 'PACF Scaled Gold Search Interest FD')
par(mfrow = c(1,1))   # revert layout changes
```
Unsurprisingly the rescaling does not matter for the autocorrelation as it is a scaled measure of linear relationships anyway.

ACF Scaled Gold Search Interest FD together with PACF Scaled Gold Search Interest FD gives evidence for an AR(4).

For the Gold Price it's ambiguous. Could be an MA, AR or an ARMA. 

```{r 4}
# Scaled non-differenced

# save variable vectors in time series format:
gold_price_scaled <- ts(gold_price_scaled, frequency = 12,
                        start = c(2004, 1), end = c(2021, 5))
gold_search_scaled <- ts(gold_search_scaled, frequency = 12,
                         start = c(2004,1), end = c(2021,5))

# set up data for estimation using `VAR()`
VAR_data_scaled <- window(ts.union(gold_price_scaled, gold_search_scaled),
                   start = c(2004, 1), end = c(2021, 5))

# estimate model coefficients using `VAR()`
VAR_est_scaled <- VAR(y = VAR_data_scaled, p = 6)        # lag order 6 is a guess
summary(VAR_est_scaled)

# augmented DF test with a trend on gold price
df_test_gold_price <- urca::ur.df(gold_price_scaled, type = c('trend'),
                       selectlags = 'AIC')
summary(df_test_gold_price)

# augmented DF test with a trend on gold search
df_test_gold_search <- urca::ur.df(gold_search_scaled, type = c('trend'),
                       selectlags = 'AIC')
summary(df_test_gold_search)
```
For the gold price we cannot reject the null of a non-stationary process (the random walk with drift+trend is the null), seems to fit conventional wisdom on prices. Prices are often thought about as following a random walk and thus being non-stationary. For the gold search index, we reject the H0, indicating a stationary porcess, given the data. 

For gold price, we look at difference-stationarity.
```{r 5}
# Scaled First-differences

# save variable vectors as time series format:
gold_price_scaled_FD <- ts(gold_price_scaled_FD, frequency = 12,
                        start = c(2004, 2), end = c(2021, 5))      #excluding first observation.
gold_search_scaled_FD <- ts(gold_search_scaled, frequency = 12,
                         start = c(2004,2), end = c(2021,5))

# set up data for estimation using `VAR()`
VAR_data_scaled_FD <- window(ts.union(gold_price_scaled_FD, gold_search_scaled_FD),
                   start = c(2004, 2), end = c(2021, 5))

# estimate model coefficients using `VAR()`
VAR_est_scaled_FD <- VAR(y = VAR_data_scaled_FD, p = 5)        #lag order 6 is a guess
summary(VAR_est_scaled_FD)


# augmented df test on only the differenced gold price
df_test_gold_price_FD <- urca::ur.df(gold_price_scaled_FD, type = 'none',
                               selectlags = 'AIC')
summary(df_test_gold_price_FD)
```
As the DF-test for the first-difference gold price rejects, we cannot say that the data is not stationary. Which gives evidence for the gold price being an I(1) process.
```{r 6}
# Unscaled Non-differenced

# save variable vectors as time series format:
gold_price <- ts(gold_price, frequency = 12,
                        start = c(2004, 1), end = c(2021, 5))
gold_search <- ts(gold_search, frequency = 12,
                         start = c(2004,1), end = c(2021,5))

# set up data for estimation using `VAR()`
VAR_data <- window(ts.union(gold_price, gold_search),
                   start = c(2004, 1), end = c(2021, 5))

# estimate model coefficients using `VAR()`
VAR_est <- VAR(y = VAR_data, p = 6, type = 'both')      #lag order 6 is a guess
summary(VAR_est)

#####################################################
####### Sollten wir hier beim AR(1) nicht die First differences verwenden.
# Weil wir ja einen I(1) prozess haben. Und sollten wir nicht einfach mit 
# dem besteren ARMA modell arbeiten und nicht AR(1) ? #####
#####################################################

# compare the VAR to the AR(1) model for the prices
T <-length(gold_price)
gold_price_2 <- as.numeric(gold_price[-1])
gold_price_lagged <- as.numeric(gold_price[-T])

plot(y=gold_price_2,x=gold_pr$DATE[1-209], type = 'l', lwd = 1, col = 'red',
     main = 'Gold Price and Lagged Gold Price',
     ylab = 'Gold Price', xlab = 'Months from 01.2004')
lines(y=gold_price_lagged,x=gold_pr$DATE[1-209], lwd = 1, col = 'blue')
legend('topleft', legend = c('Lagged Price','Price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# estimate AR(1) model
gold_price_AR1 <- lm(gold_price_2 ~ gold_price_lagged)
# estimate robust standard errors
coeftest(gold_price_AR1, vcov. = vcovHC, type = "HC1")
gold_price_AR1_check <- arima(gold_price, order = c(1,0,0)) # check if we did correctly
summary(gold_price_AR1_check) #same

# estimate MA(1)model, Auto ARIMA suggests an MA(0,1,1), see below
gold_price_MA1 <- arima(gold_price, order = c(0,0,1))
summary(gold_price_MA1)
```

```{r}
# Unscaled First-difference

# save variable vectors as time series format:
gold_price_FD <- ts(gold_price_FD, frequency = 12,
                        start = c(2004, 2), end = c(2021, 5))       # excluding first observation.
gold_search_FD <- ts(gold_search_FD, frequency = 12,
                         start = c(2004,2), end = c(2021,5))

# set up data for estimation using `VAR()`
VAR_data_FD <- window(ts.union(gold_price_FD, gold_search_FD),
                   start = c(2004, 2), end = c(2021, 5))

# estimate model coefficients using `VAR()`
VAR_est_FD <- VAR(y = VAR_data_FD, p = 6, type = 'both')    # lag order 6 is a guess
summary(VAR_est_FD)


# compare the VAR to the AR(1) model for prices first-differenced
T <-length(gold_price_FD)
gold_price_FD_2 <- as.numeric(gold_price_FD[-1])
gold_price_FD_lagged <- as.numeric(gold_price_FD[-T])

plot(y=gold_price_FD_2,x=gold_pr$DATE[3:209], type = 'l', lwd = 1, col = 'red',
     main = 'Gold Price FD and Lagged Gold Price FD',
     ylab = 'Gold Price FD', xlab = 'Months from 01.2004')
lines(y=gold_price_FD_lagged,x=gold_pr$DATE[3:209], lwd = 1, col = 'blue')
legend('topleft', legend = c('Lagged Price','Price'),
       col = c('blue','red'), bty = "n", pch = c(19,19))

# estimate AR(1) model
gold_price_FD_AR1 <- lm(gold_price_FD_2 ~ gold_price_FD_lagged)
# estimate robust standard errors
coeftest(gold_price_FD_AR1, vcov. = vcovHC, type = "HC1")
gold_price_AR1_FD_check <- arima(gold_price_FD, order = c(1,0,0)) # check if we did correctly
summary(gold_price_AR1_FD_check) # almost same

# estimate MA(1)model, what Auto ARIMA suggests MA(0,1,1) for prices and MA(0,0,1) for FD prices, see below
gold_price_MA1 <- arima(gold_price, order = c(0,0,1))
summary(gold_price_MA1)
```
The values on the intercept seem to differ, but the estimated coefficient on the lag seems to fit. 

```{r 7}
# verify the 'by-hand' results with built-in function for ARIMA
ar.ols(gold_price, order.max = 5, intercept = T)
forecast::auto.arima(gold_price, ic = 'aic')

#for FD
ar.ols(gold_price_FD, order.max = 5, intercept = T) #just verifies the above ARIMA(0,1,1)
forecast::auto.arima(gold_price_FD, ic = 'aic')
```
The model is automated to difference such that the data is stationary, then the function finds the best forecasting model via the AIC. Here this would be an ARMA(0,1) model:
  \begin{align*}
  \widehat{\Delta \text{gold price}}_t = \underset{3.6766}{(7.1279)} + \epsilon_t + \underset{(0.0740)}{(-0.1411)} \epsilon_{t-1}
  \end{align*}

```{r}
# estimate model coefficients for VAR using AIC

VAR_lag <- VAR(y = VAR_data, type = 'both', ic = 'AIC', lag.max = 15)
summary(VAR_lag)

VAR_lag_select <- VARselect(y = VAR_data, type = 'both', lag.max = 15)
VAR_lag_select

#for FD
VAR_lag_FD <- VAR(y = VAR_data_FD, type = 'both', ic = 'AIC', lag.max = 15)
summary(VAR_lag_FD)

VAR_lag_FD_select <- VARselect(y = VAR_data_FD, type = 'both', lag.max = 15)
VAR_lag_FD_select

#Problem! All roots are inside the unit circle --> unstable. This is why we try it without a trend --> type = 'const' (which would anyhow be the default)
```

```{r}
# estimate model coefficients for VAR using AIC without a trend

VAR_lag <- VAR(y = VAR_data, type = 'const', ic = 'AIC', lag.max = 15)
summary(VAR_lag)

VAR_lag_select <- VARselect(y = VAR_data, type = 'const', lag.max = 15)
VAR_lag_select

#for FD
VAR_lag_FD <- VAR(y = VAR_data_FD, type = 'const', ic = 'AIC', lag.max = 15)
summary(VAR_lag_FD)

VAR_lag_FD_select <- VARselect(y = VAR_data_FD, type = 'const', lag.max = 15)
VAR_lag_FD_select
```


```{r}
#Force it to 1 lag

# estimate model coefficients using AIC

VAR_lag <- VAR(y = VAR_data, type = 'both', p=1)
summary(VAR_lag)

#for FD
VAR_lag_FD <- VAR(y = VAR_data_FD, type = 'both', p=1)
summary(VAR_lag_FD)




VAR_lag <- VAR(y = VAR_data, type = 'const', p=1)
summary(VAR_lag)


#for FD
VAR_lag_FD <- VAR(y = VAR_data_FD, type = 'const', p=1)
summary(VAR_lag_FD)

# dowsn't change much. Still the root problem (inside unit circle)
# I think the main problem is, that we regress an I(1) on a stationary variable.
```


# Phillips-Ouliaris Cointegration Test
```{r}
po.test(VAR_data, demean = TRUE, lshort = TRUE)

# for FD
po.test(VAR_data_FD, demean = TRUE, lshort = TRUE)
```
We cannot reject the null of the residuals being I(1). Thus we cannot rule out the case of a spurious or unbalanced regression. Note: as we only have one I(1) process and one non I(1) process this test makes no real sense.

# Ideas for the first part: Univariate Time Series

# Differenced MA(1) and ARCH Model for Gold Prices
```{r}
# Differenced MA(1) and ARCH Model for Gold Prices 
gold_price_FD <- ts(gold_daily_FD, frequency = 365,
                    start = c(2001, 1, 3), end = c(2021, 6, 23))   # with higher frequency

plot(gold_price_FD, ylab = 'FD Gold Prices', col = 'red', lwd = 0.5)

arima_model_HF_FD <- forecast::auto.arima(gold_price_FD, ic = 'aic')
arima_model_HF_FD

# Auto-ARIMA suggests an ARMA(4,2) for daily prices

plot(forecast::arima.errors(arima_model_HF_FD),type = 'l', lwd = 0.5, col = 'blue',
     ylab = 'ARIMA residuals')
```
Going by the plot, it does not appear that the variance of the residuals is constant over time but rather has times of higher and lower volatility. 

```{r}
###################
##     CHECK     ##
###################

#ARCH by hand
resi_arima_FD_2 <- (forecast::arima.errors(arima_model_HF_FD))^2
arch1_FD_model <- arima(resi_arima_FD_2, order = c(1,0,0))
arch1_FD_model
AIC_ARCH_1<-AIC(arch1_FD_model)
AIC_ARCH_1



#ARCH with garch()
gold_price_FD_clean<- na.remove(gold_price_FD) #Remove NAs for garch() #### should be deleted !!! ###
gold_price_FD_arch1 <- garch(gold_price_FD_clean,c(0,1))     #ARCH   
gold_price_FD_arch1
AIC_arch_1<-AIC(gold_price_FD_arch1)
AIC_arch_1

# plot the squared residuals:
plot(resi_arima_FD_2, ylab = 'Squared ARIMA Residuals of FD Gold Price',
     xlab = 'Time from 01.2001', col = 'red', lwd = 0.5)
```

# GARCH
```{r}
#Try GARCH(1,1)
garch_gold_price_FD <- garch(x=gold_price_FD_clean,order=c(1,1))
summary(garch_gold_price_FD)

AIC_GARCH_1<-AIC(garch_gold_price_FD)
AIC_GARCH_1
```

```{r}
# Check, if the above GARCH(1,1) works with rugarch


#fit the rugarch sGarch model 
spec = ugarchspec(variance.model=list(model="sGARCH", garchOrder=c(1,1)), mean.model=list(armaOrder=c(0,0)), distribution="norm")
test_garch_gold_price_FD<- ugarchfit(spec=spec, data=gold_price_FD_clean)
test_garch_gold_price_FD

#Summarizes coeff.
coef(test_garch_gold_price_FD)

garch_gold_price_FD$coef  # for comparison with the package tseries and garch from above, Checked online. It's a common thing. I also changed the spes a lot but wasn't able to get exactly the same result

#calculating AIC:
AIC_GARCH_2 <- 6.8428*length(gold_price_FD_clean)
AIC_GARCH_2

#Plot of squared residuals and est. cond. variance
gold_price_FD_res<-test_garch_gold_price_FD@fit$residuals
gold_price_FD_var<-test_garch_gold_price_FD@fit$var
plot((gold_price_FD_res)^2, type = "l", col="blue",ylab = 'residuals^2 / variance', main="GARCH(1,1)")
lines(gold_price_FD_var, col="green")
legend('topleft', legend = c('FD Gold Price reiduals^2','FD Gold Price vairance'),
       col = c('blue','green'), bty = "n", pch = c(19,19))
```

Since rugarch uses a different version of AIC one needs to mutiply it with the length: 6.8428*6850=46873.18


```{r}
#Try eGARCH
spec = ugarchspec(variance.model=list(model="eGARCH", garchOrder=c(1,1)), mean.model=list(armaOrder=c(0,0)), distribution="norm")
egarch_gold_price_FD<- ugarchfit(spec=spec, data=gold_price_FD_clean, solver = 'hybrid')
egarch_gold_price_FD

AIC_eGARCH <- 6.8311*length(gold_price_FD_clean)
AIC_eGARCH
```

```{r}
#Try iGARCH
spec = ugarchspec(variance.model=list(model="iGARCH", garchOrder=c(1,1)), mean.model=list(armaOrder=c(0,0)), distribution="norm")
igarch_gold_price_FD<- ugarchfit(spec=spec, data=gold_price_FD_clean)
igarch_gold_price_FD

AIC_iGARCH <- 6.842*length(gold_price_FD_clean)
AIC_iGARCH
```

```{r}
# Summarizing all coeff:

coef(garch_gold_price_FD)  #GARCH t-series  
coef(test_garch_gold_price_FD) #sGARCH
coef(egarch_gold_price_FD) #eGARCH
coef(igarch_gold_price_FD)  #iGARCH

# Summarizing AICs:
AIC_arch_1 #ARCH
AIC_GARCH_1 #GARCH t-series  
AIC_GARCH_2 #sGARCH
AIC_eGARCH #eGARCH
AIC_iGARCH #iGARCH

# According to AIC it seems like eGARCH performs the best, but isn't better than MA(1)
```







